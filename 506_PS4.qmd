---
title: "STATS 506 Problem Set 4"
author: "Snigdha Pakala"
format:
  html:
    embed-resources: true
editor: visual
---

### Link to my GitHub repository:

### <https://github.com/snigdhapakala/506_ProblemSet4>

## Problem 1

### 1a:

```{r}
#install.packages("nycflights13")
library(nycflights13)
library(tidyverse)
library(dplyr)
```

```{r}
# Showing Work for 1a in this R Chunk: 

# Data in this tibble
nycflights13::flights

# Exclude those destinatios with under 10 flights:
flights_10_plus <- flights %>%
                    group_by(dest) %>%
                    filter(n() >= 10) %>%
                    summarise(flight_count = n()) %>%
                    arrange(flight_count) %>%
                    ungroup()
flights_10_plus
# 3 destinations with less than 10 flights, removed from this filtered list

# Summarize mean and median departure delays
flights_dep_stats <- flights %>%
                      group_by(dest) %>%
                        filter(n() >= 10) %>%
                      ungroup() %>%
                      group_by(origin) %>%
                        summarise(mean_dep_delay = round(mean(dep_delay, na.rm = TRUE), 1),
                                  median_dep_delay = round(median(dep_delay, na.rm = TRUE), 1)
                                  )%>%
                        arrange(desc(mean_dep_delay)) %>%
                      ungroup()

# Sanity check
row_count_origin <- flights %>% 
                    distinct(origin) # We're good!

# Display airport name and not code:

# Airport names is shown in this tibble: faa in airports has information that origin does
nycflights13::airports

airport_names <- flights_dep_stats %>%
                left_join(airports, join_by("origin" == "faa"))
```

```{r}
# Display results for 1a neatly:

# Departures tibble
departures <- flights_dep_stats %>%
              left_join(airports, join_by("origin" == "faa")) %>%
              select(name, mean_dep_delay, median_dep_delay)
#########################################################################

# Arrivals tibble: same process as above, just altogether since I know it works
arrivals <- flights %>%
            group_by(dest) %>%
              filter(n() >= 10) %>%
              summarise(mean_arr_delay = round(mean(arr_delay, na.rm = TRUE), 1),
                        median_arr_delay = round(median(arr_delay, na.rm = TRUE), 1)) %>%
              arrange(desc(mean_arr_delay)) %>%
            ungroup() %>%
            left_join(airports, join_by("dest" == "faa")) %>%
            select(name, mean_arr_delay, median_arr_delay)
```

### 1b:

```{r}
# Calculate speed since we don't have it
speed <- flights %>%
          mutate(speed_mph = distance / (air_time / 60)) %>% 
          select(distance, air_time, speed_mph) # Correct calculation!

# Model in planes tibble, left join and combine speed calc from above
fastest_plane <- flights %>%
                  mutate(speed_mph = distance / (air_time / 60)) %>% 
                  left_join(planes, join_by("tailnum" == "tailnum")) %>%
                  group_by(model) %>% # For each model, get the average speed and flight count
                    summarise(avg_speed_mph = round(mean(speed_mph, na.rm = TRUE), 1),
                              num_flights = n()) %>%
                    arrange(desc(avg_speed_mph)) %>% # Sort data by fastest speed 1st
                    slice(1) %>% # Limit output by row with largest average speed
                    select(model, avg_speed_mph, num_flights) %>% # Only displaying relevant rows
                  ungroup()
fastest_plane
```

Answer: The aircraft model with the fastest average speed was 777-222 with 482.6 mph on average, and it took 4 flights.

## Problem 2:

```{r}

#' Title This function will provide the average temperature for a requested month
#'
#' @param month numeric 1-12 or a string
#' @param year numeric year
#' @param data dataset to obtain the data from
#' @param celsius whether temperature should be in celsius. Default is false
#' @param average_fn function with which to compute the mean. Default is mean()
#'
#' @return A numeric vector of length 1 that returns the temperature in the given month or provides an error when incorrect input is provided
#' @export
#'
#' @examples
get_temp <- function(month, year, data, celsius = FALSE, average_fn = mean) {

  # Provide correct month and abreviations to match to later
  correct_months <- c("January", "February", "March", "April", "May", "June", 
                     "July", "August", "September", "October", "November", "December")
  correct_month_abbrs <- substr(correct_months, 1, 3)
  
  # If month is a string, make sure it is valid, and convert to month number. Otherwise, if it's not numeric, or a valid number 1 through 12, error out.
  if (month %>% is.character) {
    if (month %in% correct_months) {
      month <- match(month, correct_months)  # Extract month number from month name
    } else if (month %in% correct_month_abbrs) {
      month <- match(month, correct_month_abbrs)  # Extract month number from abbreviation 
    }
  }
  else if (month %>% is.numeric) {
    if (month < 1 || month > 12) {
      stop("Month number must be between 1 and 12 to be valid.")
    }
  }
  else{
    stop("Month should be a number between 1 and 12, or a valid month name or 3-letter abbreviation.")
  }
  
  # Check input to see if year is valid: numeric and between 1997 and 2000 inclusive, since this is what we have in the data
  if (!(year %>% is.numeric)) {
    stop("Year should be a 4 digit numeric number ")
  }
  if (!(year %in% 1997:2000)) {
    stop("Data only has years 1997 through 2000. No data on temperatures outside of this range.")
  }
  
  # Seems implicit that data is nmmaps, will ignore checking this
  
  # Check celsius is either left blank or logical: check if there is an input provided by the user, and if so, ensure it is a logical
  if (!(celsius %>% is.logical()) || length(celsius) != 1) {
    stop("The 'celsius' argument must be either 'TRUE' or 'FALSE'.")
  }
  
  # Check that average_fn is a function
  if (!(average_fn %>% is.function)) {
    stop("average_fn must be a function")
  }
  
  temp_result <- data %>%
    rename(year_data = year) %>% # Was getting an error if I didn't differentiate between input year and year column in the data
    filter(year_data == !!year, month_numeric == !!month) %>%
    summarise(avg_temp = average_fn(temp))  %>%
    mutate(avg_temp = if_else(celsius, (avg_temp - 32) * (5/9), avg_temp)) %>%
    select(avg_temp) %>%
    as.numeric
  
  return(temp_result)
  
}

nnmaps = read.csv("chicago-nmmaps.csv")

# Test cases to ensure it works:

# get_temp("Apr", 1999, data = nnmaps)
# get_temp("Apr", 1999, data = nnmaps, celsius = TRUE)
# get_temp(10, 1998, data = nnmaps, average_fn = median)
# get_temp(13, 1998, data = nnmaps) # Errors out
# get_temp(2, 2005, data = nnmaps) # Errors out
# get_temp("November", 1999, data =nnmaps, celsius = TRUE, average_fn = function(x) {
#            x %>% sort -> x
#            x[2:(length(x) - 1)] %>% mean %>% return
#          })


```

## Problem 3

### 3a: Change in sales price over time

```{r}
# Load necessary libraries
# Libraries
library(ggplot2)
library(dplyr)

art_sales <- read.csv("df_for_ml_improved_new_market.csv")
summary(art_sales$price_usd)
min(art_sales$year)
max(art_sales$year)
# 15 years of data here, let's group by year and see the trend of the price_usd

art_sales_by_year <- art_sales %>%
  group_by(year) %>%
  summarize(avg_sales_price = mean(price_usd, na.rm = TRUE)) %>%
  ungroup()


ggplot(art_sales_by_year, aes(x = year, y = avg_sales_price)) +
  geom_line(color = "brown4", size = 1) +
  geom_point(color = "brown4", size = 2) +
  geom_smooth(method = "loess", color = "blue", fill = "bisque2", linetype = "dashed") +
  labs(
    title = "Average Sales Price in USD Over Time",
    x = "Year",
    y = "Average Sales Price (USD)"
  ) +
  theme_minimal() +
  theme(
    text = element_text(size = 14),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )
```

To answer a question about whether the USD price is changing over time, a line plot with years on the X axis and average yearly USD price on the Y axis can help identify trends over time and reveal increases/decreases in price, justifying my approach for this problem. Looking at this plot, we see that there is an overall change in the sales price in USD over time, and this trend is mostly increasing. In 1997 the average sales price was under \$10,000 and in 2012 it was about 3 times that much, despite accounting for a dip in prices from a few years prior. In order to better see this trend, I used a smoothing Loess function in my plot, which helps clearly see that the general trend of prices over the years is that they have been increasing. Now some might argue that average prices started declining around 2008 and this is no longer an upwards trend. However, until we have more data over time, we cannot make a claim that this drop will continue to happen, or something like this trend follows a sine curve. Thus, with the data at hand, the trend shows that prices have definitely increased over time from what they were. This might be due to a growing demand for art, increased globalization and technology allowing for more artists' work to be noticed by the public, inflation and other economic trends. This graph does a great job of showing that in general, average sale prices have increased over the 15 years data was collected.

### 3b:

```{r}

library(ggplot2)
library(dplyr)

art_sales_long <- art_sales %>%
  pivot_longer(cols = starts_with("Genre__"), names_to = "Genre", values_to = "Sales") %>%
  filter(Sales == 1) %>%  # Filter only where genre is marked as 1
  mutate(Genre = str_replace(Genre, "Genre___", "")) %>%  # Remove "Genre___" prefix 
  count(year, Genre) %>%
  group_by(year) %>%
  mutate(Proportion = (n / sum(n)))  # Calculate proportion per year


ggplot(art_sales_long, aes(x = year, y = Proportion, fill = Genre)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(title = "Distribution of Art Sales by Genre Across Years",
       x = "Year",
       y = "Proportion of Sales",
       fill = "Genre") +
  theme_minimal(base_size = 14) +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

The important aspect of this graph is that it needs to measure art sales across different Genres over time, so that's 3 different aspects of the data to simultaneously look at. With something like this, a stacked bar plot made the most sense to me. Each year is a bar plot where the different colors signify the different genres, and the proportion of that color in that bar is significant to the proportion of art sales within that genre in that year. This gives us a quick look at changes for each genre in art sales over time. For instance, through this we can say the following:

-   The painting genre has declined in proportion of art sales compared to the other genres over time, while photography has increased in proportion of art sales over time.

-   Within all the art sales in 2000, sculpture made up the highest proportion of art sales while print made up the lowest proportion.

Something to keep in mind is combining with the previous visual, since there was a general increase in art sales, the proportions per year in this stacked bar plot might be misleading because they don't visually address that increase in sales over time. For instance, between 2007 and 2008, photography art sales might have taken up similar proportions of each year, but since we know from plot 1 that average sale prices peaked in 2008, there might be a significant difference in the absolute dollar amount of photography sales between the two years.

Since this question asks about the distribution of genre of sales over time, this plot suffices in helping us answer. I would say that the distribution of genre of sales over time changes quite a bit till 2001. From 1997 to 2001 there are more obvious changes in trends (proportion of art sales of "other" and "paintings" genres declined a good amount, while the proportion of art sales of "photography" began increasing. But 2001 onwards, the proportions of each of these genres seems to be, in general, pretty constant in yearly art sales. So I would say no, the distribution of genre of sales across years does not appear to change, especially after 2001.

### 3c:

```{r}

# Calculate average sale price per genre per year
average_price_genre <- art_sales %>%
  pivot_longer(cols = starts_with("Genre__"), names_to = "Genre", values_to = "Sales") %>%
  filter(Sales == 1) %>%  # Keep only rows where a genre is marked as sold
  mutate(Genre = str_replace(Genre, "Genre___", "")) %>%
  group_by(year, Genre) %>%
  summarize(Average_Price = mean(price_usd, na.rm = TRUE), .groups = "drop")

# Plotting average sale price over time for each genre
ggplot(average_price_genre, aes(x = year, y = Average_Price, color = Genre, group = Genre)) +
  geom_line(size = 1) +
  geom_point() +
  scale_color_brewer(palette = "Pastel1") +
  labs(title = "Average Sale Price by Genre Over Time",
       x = "Year",
       y = "Average Sale Price (USD)",
       color = "Genre") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

This chart does a good job of combining aspects from the previous 2 charts to show trends in pricing over time that are specific to each genre. It’s a more detailed look at how the art sale price of each genre changes over time, rather than the genre’s share of total art sales. Now we can see that the photography genre is largely responsible for the upwards trend in art sale pricing over time. If it wasn't for photography, our change in art sale prices around 2008 would not be as easily discernable. The other 4 genres have very similar average sale prices following the anomalously high 2008 prices. This implies that the peak in sales in the first graph is likely due to the rise in photographic art demand rather than natural, slower price increases such as inflation and economic ebbs and flows. Another interesting aspect to note is the difference in impact seen in the printing genre on sales in this chart. In the previous one, printing was always overshadowed by the higher proportion genres. But here, we can see it had a high impact on those peaks in 2002 and 2004 seen in chart 1. All 5 genres' sale prices shot up in 2008 which implies that there's potentially another lurking variable that will explain all 5 genres being at their peaks in the same year. Sculpture trends, although also generally increasing, are increasing at the lowest rate compared to the other genres. Finally, the "other" genre and painting genre follow an extremely similar trend over time for their sale price averages.

### Attribution of Sources:

-   1a: <https://dplyr.tidyverse.org/reference/mutate-joins.html> Used this to figure out how to join the airport names to the flight codes, especially with using "join_by"
-   1b: <https://dplyr.tidyverse.org/reference/slice.html> using slice for limiting the rows that get outputted
-   2: <https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/match> Used this to convert month names to month counts if user entered name or abbreviation
-   2: <https://stackoverflow.com/questions/70518374/how-to-use-pipe-in-r-with-dollar-sign> the as.list helped me realize how to incorporate more piping especially when I was checking for the type of inputs
-   2: <https://www.r-bloggers.com/2019/07/bang-bang-how-to-program-with-dplyr/#google_vignette> wanted to use the bang-bang operator to pass non-standard evaluation variables into a tidyverse function, so that year and month could be evaluated as their actual values rather than being treated as literal variable names
-   3a: [https://mgimond.github.io/ES218/bivariate.html#:\~:text=The%20loess%20fit%20can%20be,)%2](https://mgimond.github.io/ES218/bivariate.html#:~:text=The%20loess%20fit%20can%20be,)%2C%20and%20degree%20(%20).&text=The%20modeled%20loess%20curve%20can,plot%20using%20the%20lines%20function.&text=In%20ggplot2%20simply%20pass%20the,parameter%20to%20the%20stat_smooth%20function.)
-   [C%20and%20degree%20(%20).&text=The%20modeled%20loess%20curve%20can,plot%20using%2](https://mgimond.github.io/ES218/bivariate.html#:~:text=The%20loess%20fit%20can%20be,)%2C%20and%20degree%20(%20).&text=The%20modeled%20loess%20curve%20can,plot%20using%20the%20lines%20function.&text=In%20ggplot2%20simply%20pass%20the,parameter%20to%20the%20stat_smooth%20function.)
-   [0the%20lines%20function.&text=In%20ggplot2%20simply%20pass%20the,parameter%20to%20the](https://mgimond.github.io/ES218/bivariate.html#:~:text=The%20loess%20fit%20can%20be,)%2C%20and%20degree%20(%20).&text=The%20modeled%20loess%20curve%20can,plot%20using%20the%20lines%20function.&text=In%20ggplot2%20simply%20pass%20the,parameter%20to%20the%20stat_smooth%20function.)
-   [%20stat_smooth%20function.](https://mgimond.github.io/ES218/bivariate.html#:~:text=The%20loess%20fit%20can%20be,)%2C%20and%20degree%20(%20).&text=The%20modeled%20loess%20curve%20can,plot%20using%20the%20lines%20function.&text=In%20ggplot2%20simply%20pass%20the,parameter%20to%20the%20stat_smooth%20function.) while reading this for EDA inspiration, I came about the code for the Loess smoothing function and figured it would be useful in visualizing the overall trend to answer this question
-   3a: <https://sape.inf.usi.ch/quick-reference/ggplot2/colour> used for the ggplot colors
-   3b: <https://r-graph-gallery.com/38-rcolorbrewers-palettes.html> used for scale_fill_brewer pallette in ggplot
